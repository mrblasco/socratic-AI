\clearpage
\processdelayedfloats
\clearpage
\appendix
\setcounter{table}{0}
\setcounter{figure}{0}
\renewcommand{\thetable}{A\arabic{table}}
\renewcommand{\thefigure}{A\arabic{figure}}

```{r setup-SI, include = FALSE}
require(kableExtra)
```

# Supporting Information 

## AI Explanation {#sec:si-ai-explanation}

Table \@ref(tab:explanation) presents the text shown to participants in the "AI with Explanation" treatment. This was generated by prompting GPT-4.0 with an image of a coin-filled jar with the following prompt: "What is your best guess of the total value of coins in the jar pictured in this image? Answer with a  concise step-by-step procedure understandable for an 8th-grade student and a number representing the estimated total value." 

The image was from the article, "Turns Out the Internet Is Bad at Guessing How Many Coins Are in a Jar" [@steiner2015turns]. Notice that, since we couldn't assume students were familiar with the U.S. coins, in the experiment we combined the jar picture with another image illustrating the coin denominations.

```{r explanation}
df_reasoning <- data.frame(
  Step = c("Introduction", "Estimate the volume of the jar", "Estimate the volume of a single coin", "Convert to dollars"),
  Explanation = c("To estimate the total value of the coins in the jar, let's go through a step-by-step process.", "The jar in the image resembles a standard large water bottle, possibly around 5 gallons (18.93 liters) in volume. Since the coins don't fill the jar completely, we estimate they occupy about 1/4 of the jar. Therefore, the volume filled by coins is approximately 1.25 gallons or about 4.73 liters.", "Assuming most coins are US pennies, with a volume of around 0.36 cubic centimeters, we need to determine how many pennies could fit into the 4.73-liter volume (4730 cubic centimeters).", "Finally, we convert the total number of pennies to dollars: 21350 pennies ÷ 100 = $213.50. Therefore, a rough estimation of the total value of the coins in the jar might be around $213.50.")
)
kbl(df_reasoning, booktabs = TRUE, caption = "AI's Step-by-Step Reasoning for Estimating the Value of Coins in a Jar") |> 
kableExtra::column_spec(2, width = "4in")
```
\newpage

<!-- 
## Task descriptions {#sec:tasks}

Students were asked to perform three different tasks, reflecting different skills. The tasks are described below

- **Task 1. Guessing water consumption:** In this task, students were presented with a real-world estimation problem that required them to generate rough, logical estimates rather than precise answers. These problems, known as Fermi Problems, demand critical thinking and are commonly used to test the reasoning ability. Previous research has shown that AI models struggle with such open-ended problems [@kalyan2021how], but this task allowed us to assess how interacting with either AI tutor affected students' ability to reason through the challenges.

- **Taks 2: Discussing a topic and writing an essay:** In this task, students were asked to discuss a given topic with the AI tutor and then write a short essay, of at least XXXX words, about it. The essay-writing task assessed students’ ability to engage with complex ideas, structure their thoughts, and express their arguments clearly. The AI tutors facilitated the discussion prior to the essay, allowing us to evaluate how each pedagogical approach—Socratic or non-Socratic—influenced the depth and quality of the students' written responses. 

- **Task 3: Explaining sound waves propagation** The final tasks involved answering basic conceptual physics questions, such as explaining how the sound propagates through different media or identify factors that affect sound propagation. This task tested students' understanding of scientific concepts and their ability to apply new conceptual knowledge. By comparing the responses of students who interacted with the Socratic and non-Socratic AI tutors, we aimed to determine whether one approach led to better conceptual understanding and retention of scientific knowledge. -->

## Regression analysis for differences in students confidence {#sec:regress-confidence}

We analyzed the impact of Socratic AI versus Non-Socratic AI on student $i$'s outcomes after task $j$, $Y_{ij}$, using different specifications based on following ordinal regression model:
$$
  P(Y_{ij} = k) = 
    \beta_0 + \beta_1 \text{self-efficacy}_{ij} + \gamma T_{i} 
    + \delta_j + \eta_i + \epsilon_{ij}.
$$
Where:

- $P(Y_{ij} \leq k)$ represents the cumulative probability for $Y_{ij}$ and $P(Y_{ij} = k)$ is the probability that the self-reported confidence level or perceived helpfulness of student $i$ for task $j$ falls at a certain point $k$.

- $\text{self-efficacy}_{ij}$ is the student $i$'s self-efficacy relevant for task $j$ (i.e., perceived ability to peform the task)

- $T_i$ indicates the AI tutor assigned to student $i$ (1 = Socratic or 0 = non-Socratic).

- $\delta_j$ is a random effect associated with task $j$, accounting for task-specific variation.

- $\eta_i$ is a random effect associated with student $i$, capturing individual-level differences.

- $\epsilon_{ij}$ is the error term.

<!-- Figure \@ref(fig:socratic-effects) displays the results for both outcomes. For simplicity, we reported results from a specification where the confidence variable is binary, categorized as "confident" when the response was greater than the mid point of the scale, and "not confident" otherwise. Similarly, we binarised to "helpful" or "not helpful" the other variable. Nevertheless, similar results were obtained using Ordinal Logistic Regression.  -->

<!-- ![Regression coefficients and 95% confidence intervals from a linear regression using as dependent variable the (**A**) students' self-reported confidence level and (**B**) perceived helpfulness of the AI tutor. The controls include task type, student's gender, grades, location, and ChatGPT experience. All models also include individual student random effects, and the student's response to questions about their confidence in their skills before performing each task.](11_socratic_regression.pdf){#fig:socratic-effects} -->

The regression specification described above assumes homogeneous treatment effects across individuals and tasks. To relax this assumption, we employed a more flexible model that allows the average treatment effect, $\gamma$, to vary based on individual-level and task-specific factors. Specifically, we included interaction terms between the treatment indicator and variables such as the student’s gender, academic performance (as measured by school grades), prior experience with ChatGPT, and school location. Additionally, we accounted for heterogeneity in treatment effects across tasks by estimating separate regressions for each task-specific subset of the data. The results are shown in Figure \@ref(fig:interactions), Figure \@ref(fig:confidence-regression), and Figure \@ref(fig:helpful-regression).

